import pandas as pd
import numpy as np
import os
import glob
from scipy.stats import linregress
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import LeaveOneOut
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import warnings
from pathlib import Path
import sys
from sklearn.feature_selection import RFECV # å¯¼å…¥ RFECV

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå¿½ç•¥è­¦å‘Š
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore')

class BatteryLifePredictionModel:
    def __init__(self, data_folder=None, num_early_cycles=40):
        """
        åˆå§‹åŒ–ç”µæ± å¯¿å‘½é¢„æµ‹æ¨¡å‹
        
        Args:
            data_folder: æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æŸ¥æ‰¾
            num_early_cycles: ä½¿ç”¨çš„æ—©æœŸå¾ªç¯æ•°æ®é‡
        """
        self.num_early_cycles = num_early_cycles
        self.data_folder = self._find_data_folder(data_folder)
        self.feature_scaler = StandardScaler() # è™½ç„¶ç›®å‰æ²¡ç”¨ï¼Œä½†ä¿ç•™
        self.target_scaler = StandardScaler()
        self.model = None
        self.results = {}
        self.selected_feature_indices = None # æ–°å¢ï¼šå­˜å‚¨RFEé€‰æ‹©çš„ç‰¹å¾ç´¢å¼•
        self.engineered_feature_names = [] # æ–°å¢ï¼šå­˜å‚¨å·¥ç¨‹ç‰¹å¾åç§°

    def _find_data_folder(self, data_folder):
        """è‡ªåŠ¨æŸ¥æ‰¾æ•°æ®æ–‡ä»¶å¤¹"""
        if data_folder and os.path.exists(data_folder):
            return data_folder
            
        # å¯èƒ½çš„æ•°æ®è·¯å¾„
        possible_paths = [
            "./normalized_features",
            "../normalized_features", 
            "./data/normalized_features",
            "../data/normalized_features",
            "/home/jihn/battery-charging-data-of-on-road-electric_vehicles/normalized_features"
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                csv_files = glob.glob(os.path.join(path, "*.csv"))
                if csv_files:
                    print(f"æ‰¾åˆ°æ•°æ®æ–‡ä»¶å¤¹: {path}")
                    return path
                    
        raise FileNotFoundError("æœªæ‰¾åˆ°åŒ…å«CSVæ–‡ä»¶çš„æ•°æ®æ–‡ä»¶å¤¹ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šdata_folderå‚æ•°")

    def load_csv_data(self):
        """åŠ è½½CSVæ•°æ®"""
        csv_files = glob.glob(os.path.join(self.data_folder, "*.csv"))
        csv_files = sorted(csv_files)
        
        if not csv_files:
            raise FileNotFoundError(f"åœ¨ {self.data_folder} ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")
            
        print(f"æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
        
        early_cycle_data_list = []
        final_cycle_counts = []
        file_names = []
        
        for file_path in csv_files:
            try:
                # å°è¯•ä¸åŒçš„ç¼–ç æ–¹å¼è¯»å–CSV
                df_full = None
                for encoding in ['utf-8', 'gbk', 'gb2312', 'latin-1']:
                    try:
                        df_full = pd.read_csv(file_path, encoding=encoding)
                        break
                    except UnicodeDecodeError:
                        continue
                
                if df_full is None:
                    print(f"è­¦å‘Š: æ— æ³•è¯»å–æ–‡ä»¶ {file_path}")
                    continue
                
                # æ£€æŸ¥æ•°æ®æ ¼å¼
                if df_full.shape[1] < 15:
                    print(f"è­¦å‘Š: æ–‡ä»¶ {file_path} åˆ—æ•°ä¸è¶³15åˆ—ï¼Œè·³è¿‡")
                    continue
                
                total_cycles = len(df_full)
                num_cycles_to_read = min(self.num_early_cycles, total_cycles)
                
                # æå–å‰15åˆ—ä½œä¸ºç‰¹å¾
                early_features = df_full.iloc[:num_cycles_to_read, :15].values
                
                # æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦æœ‰æ— æ•ˆå€¼
                if np.any(np.isnan(early_features)) or np.any(np.isinf(early_features)):
                    # å¡«å……æ— æ•ˆå€¼
                    early_features = np.nan_to_num(early_features, nan=0.0, posinf=1.0, neginf=-1.0)
                
                cycle_numbers = np.arange(1, num_cycles_to_read + 1).reshape(-1, 1)
                early_data_with_cycle = np.hstack((early_features, cycle_numbers))
                
                early_cycle_data_list.append(early_data_with_cycle)
                final_cycle_counts.append(total_cycles)
                file_names.append(os.path.basename(file_path))
                
                print(f"å¤„ç†å®Œæˆ: {os.path.basename(file_path)} - æ—©æœŸæ•°æ®å½¢çŠ¶: {early_data_with_cycle.shape}, æœ€ç»ˆå¾ªç¯æ•°: {total_cycles}")
                
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        if not early_cycle_data_list:
            raise ValueError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®æ–‡ä»¶")
            
        final_cycle_counts = np.array(final_cycle_counts)
        
        print(f"\næ•°æ®åŠ è½½å®Œæˆ!")
        print(f"æˆåŠŸåŠ è½½ {len(early_cycle_data_list)} ä¸ªç”µæ± æ ·æœ¬çš„æ—©æœŸå¾ªç¯æ•°æ®")
        print(f"æœ€ç»ˆå¾ªç¯æ•°æ•°ç»„å½¢çŠ¶: {final_cycle_counts.shape}")
        
        return early_cycle_data_list, final_cycle_counts, file_names

    def extract_battery_level_features(self, early_cycle_data_list, file_names):
        """æå–ç”µæ± çº§åˆ«ç‰¹å¾"""
        X_engineered = []
        print(f"\nå¼€å§‹ç‰¹å¾å·¥ç¨‹...")
        
        # ç”Ÿæˆç‰¹å¾åç§°åˆ—è¡¨ï¼Œç”¨äºRFEåçš„ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
        self.engineered_feature_names = []
        statistic_names = ['Mean', 'Std', 'Min', 'Max', 'First', 'Last', 'Slope']
        num_original_features = 16 # 15ä¸ªåŸå§‹ç‰¹å¾ + 1ä¸ªå¾ªç¯æ•°ç‰¹å¾
        for i in range(num_original_features):
            original_feature_name = f'Original_F{i}' if i < 15 else 'Cycle_Number'
            for stat_name in statistic_names:
                self.engineered_feature_names.append(f'{original_feature_name}_{stat_name}')

        for i, battery_data in enumerate(early_cycle_data_list):
            engineered_features_for_this_battery = []
            
            for feature_idx in range(battery_data.shape[1]):
                feature_series = battery_data[:, feature_idx]
                
                if len(feature_series) > 0:
                    # åŸºæœ¬ç»Ÿè®¡ç‰¹å¾
                    engineered_features_for_this_battery.append(np.mean(feature_series))
                    engineered_features_for_this_battery.append(np.std(feature_series) if len(feature_series) > 1 else 0.0)
                    engineered_features_for_this_battery.append(np.min(feature_series))
                    engineered_features_for_this_battery.append(np.max(feature_series))
                    engineered_features_for_this_battery.append(feature_series[0])
                    engineered_features_for_this_battery.append(feature_series[-1])
                    
                    # è¶‹åŠ¿ç‰¹å¾
                    if len(feature_series) > 1:
                        if feature_idx == 15:  # Cycle number feature
                            x_values = feature_series
                        else:
                            x_values = np.arange(1, len(feature_series) + 1)
                        
                        try:
                            slope, _, _, _, _ = linregress(x_values, feature_series)
                            if np.isnan(slope) or np.isinf(slope):
                                slope = 0.0
                        except:
                            slope = 0.0
                        
                        engineered_features_for_this_battery.append(slope)
                    else:
                        engineered_features_for_this_battery.extend([0.0] * 7)
                else:
                    engineered_features_for_this_battery.extend([0.0] * 7)
            
            X_engineered.append(engineered_features_for_this_battery)
            
            if (i + 1) % 10 == 0:
                print(f"  å·²å¤„ç† {i + 1}/{len(early_cycle_data_list)} ä¸ªç”µæ± æ ·æœ¬")
        
        X_engineered_array = np.array(X_engineered)
        
        # æ£€æŸ¥ç‰¹å¾æ•°ç»„ä¸­çš„æ— æ•ˆå€¼
        if np.any(np.isnan(X_engineered_array)) or np.any(np.isinf(X_engineered_array)):
            X_engineered_array = np.nan_to_num(X_engineered_array, nan=0.0, posinf=1.0, neginf=-1.0)
            print("è­¦å‘Š: æ£€æµ‹åˆ°å¹¶ä¿®å¤äº†ç‰¹å¾æ•°ç»„ä¸­çš„æ— æ•ˆå€¼")
        
        print(f"ç‰¹å¾å·¥ç¨‹å®Œæˆ! æœ€ç»ˆå·¥ç¨‹ç‰¹å¾å½¢çŠ¶: {X_engineered_array.shape}")
        return X_engineered_array

    def train_and_evaluate_model_loocv(self, X_engineered, final_cycle_counts):
        """ä½¿ç”¨ç•™ä¸€æ³•äº¤å‰éªŒè¯è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹"""
        print(f"\nå¼€å§‹æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼° (LOOCV)...")
        print(f"è¾“å…¥ç‰¹å¾å½¢çŠ¶: {X_engineered.shape}, ç›®æ ‡å˜é‡å½¢çŠ¶: {final_cycle_counts.shape}")

        X_raw = X_engineered
        print(f"ä½¿ç”¨åŸå§‹ç‰¹å¾ï¼Œæ— æ ‡å‡†åŒ–. Xçš„å‡å€¼å’Œæ ‡å‡†å·®: {np.mean(X_raw):.2f}, {np.std(X_raw):.2f}")

        y_log1p = np.log1p(final_cycle_counts)  # log1på˜æ¢
        print(f"ç›®æ ‡å˜é‡log1på˜æ¢å®Œæˆ. å˜æ¢åYçš„èŒƒå›´: [{np.min(y_log1p):.4f}, {np.max(y_log1p):.4f}]")
        
        y_scaled = self.target_scaler.fit_transform(y_log1p.reshape(-1, 1)).flatten()
        print(f"ç›®æ ‡å˜é‡æ ‡å‡†åŒ–å®Œæˆ. æ ‡å‡†åŒ–åYçš„å‡å€¼å’Œæ ‡å‡†å·®: {np.mean(y_scaled):.2f}, {np.std(y_scaled):.2f}")
        
        # å®šä¹‰åŸºç¡€æ¨¡å‹ï¼ŒRFEå°†ç”¨å®ƒæ¥è¯„ä¼°ç‰¹å¾é‡è¦æ€§
        base_estimator = RandomForestRegressor(
            n_estimators=200,
            max_depth=15,
            min_samples_split=2,
            min_samples_leaf=1,
            max_features=1.0, # è¿™é‡Œçš„max_featuresæ˜¯RFEå†…éƒ¨æ¯æ¬¡è®­ç»ƒæ—¶RFä½¿ç”¨çš„ç‰¹å¾æ¯”ä¾‹
            bootstrap=True,
            oob_score=False, # RFE/RFECVå†…éƒ¨è¿›è¡ŒCVï¼Œoob_scoreåœ¨è¿™é‡Œä¸ç›´æ¥ä½¿ç”¨
            warm_start=False, # RFE/RFECVå†…éƒ¨ä¼šå¤šæ¬¡è®­ç»ƒï¼Œè¿™é‡Œè®¾ç½®ä¸ºFalse
            random_state=123,
            n_jobs=-1,
            min_weight_fraction_leaf=0.0,
        )

        # åˆ›å»ºRFECVå®ä¾‹
        # scoring='neg_mean_squared_error' æ˜¯å›å½’ä»»åŠ¡å¸¸ç”¨çš„è¯„åˆ†ï¼ŒRFECVä¼šå°è¯•æœ€å¤§åŒ–è¿™ä¸ªå€¼
        # cv=loo æ„å‘³ç€RFECVåœ¨å†…éƒ¨è¿›è¡Œç‰¹å¾é€‰æ‹©æ—¶ä¹Ÿä½¿ç”¨ç•™ä¸€æ³•
        print("\nå¼€å§‹RFECVç‰¹å¾é€‰æ‹©...")
        rfe_selector = RFECV(
            estimator=base_estimator,
            step=1, # æ¯æ¬¡æ¶ˆé™¤ä¸€ä¸ªç‰¹å¾
            cv=LeaveOneOut(), # ä½¿ç”¨LOOCVè¿›è¡Œç‰¹å¾é€‰æ‹©
            scoring='neg_mean_squared_error', # è¯„ä¼°æ ‡å‡†
            n_jobs=-1 # å¹¶è¡Œå¤„ç†
        )
        rfe_selector.fit(X_raw, y_scaled) # åœ¨æ‰€æœ‰æ•°æ®ä¸Šè¿›è¡Œç‰¹å¾é€‰æ‹©

        self.selected_feature_indices = rfe_selector.support_
        selected_feature_count = self.selected_feature_indices.sum()
        print(f"RFECVé€‰æ‹©çš„æœ€ä½³ç‰¹å¾æ•°é‡: {selected_feature_count}")
        print(f"æœ€ä½³ç‰¹å¾çš„æ’åï¼ˆ1è¡¨ç¤ºé€‰ä¸­ï¼‰: {rfe_selector.ranking_}")

        # è¿‡æ»¤ç‰¹å¾ï¼Œåªä¿ç•™è¢«RFECVé€‰ä¸­çš„ç‰¹å¾
        X_selected = X_raw[:, self.selected_feature_indices]
        print(f"ä½¿ç”¨RFECVé€‰æ‹©çš„ç‰¹å¾è¿›è¡Œè®­ç»ƒï¼Œæ–°ç‰¹å¾å½¢çŠ¶: {X_selected.shape}")

        # åˆ›å»ºæœ€ç»ˆçš„éšæœºæ£®æ—æ¨¡å‹ï¼Œç°åœ¨å®ƒå°†åªåœ¨é€‰å®šçš„ç‰¹å¾ä¸Šè®­ç»ƒ
        self.model = RandomForestRegressor(
            n_estimators=500,
            max_depth=20,
            min_samples_split=2,
            min_samples_leaf=1,
            max_features=1.0, # è¿™é‡Œçš„max_featuresæ˜¯RFåœ¨é€‰å®šç‰¹å¾å­é›†å†…éƒ¨çš„æ¯”ä¾‹
            warm_start=True,
            random_state=123,
            n_jobs=-1,
            min_weight_fraction_leaf=0.0,
        )

        # ç•™ä¸€æ³•äº¤å‰éªŒè¯ (ç°åœ¨åœ¨é€‰å®šçš„ç‰¹å¾ä¸Šè¿›è¡Œ)
        loo = LeaveOneOut()
        y_true_all = []
        y_pred_all = []
        
        total_folds = len(X_selected) # æ³¨æ„è¿™é‡Œæ˜¯X_selected
        for i, (train_index, test_index) in enumerate(loo.split(X_selected)): # æ³¨æ„è¿™é‡Œæ˜¯X_selected
            X_train, X_test = X_selected[train_index], X_selected[test_index]
            y_train, y_test = y_scaled[train_index], y_scaled[test_index]

            self.model.fit(X_train, y_train)
            y_pred_fold_scaled = self.model.predict(X_test)
            
            y_true_all.extend(y_test)
            y_pred_all.extend(y_pred_fold_scaled)
            
            if (i + 1) % 10 == 0:
                print(f"  å·²å®Œæˆ {i + 1}/{total_folds} æŠ˜äº¤å‰éªŒè¯")
    
        # è½¬æ¢å›åŸå§‹å°ºåº¦
        y_true_log1p = self.target_scaler.inverse_transform(np.array(y_true_all).reshape(-1, 1)).flatten()
        y_pred_log1p = self.target_scaler.inverse_transform(np.array(y_pred_all).reshape(-1, 1)).flatten()
        
        y_true_original = np.expm1(y_true_log1p)
        y_pred_original = np.expm1(y_pred_log1p)
        
        y_pred_original = np.maximum(y_pred_original, 0)

        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        overall_rmse = np.sqrt(mean_squared_error(y_true_original, y_pred_original))
        overall_mae = mean_absolute_error(y_true_original, y_pred_original)
        overall_r2 = r2_score(y_true_original, y_pred_original)

        print(f"\n{'='*60}")
        print(f"LOOCV éšæœºæ£®æ—æ¨¡å‹è¯„ä¼°ç»“æœ (åŸå§‹å°ºåº¦ï¼Œä½¿ç”¨log1på˜æ¢ï¼Œç»è¿‡RFECVç‰¹å¾é€‰æ‹©)")
        print(f"{'='*60}")
        print(f"  RMSE: {overall_rmse:.4f}")
        print(f"  MAE:  {overall_mae:.4f}")
        print(f"  RÂ² Score: {overall_r2:.4f}")
        
        print(f"\né¢„æµ‹ç¤ºä¾‹ (å‰10ä¸ªæ ·æœ¬):")
        print(f"{'å®é™…å€¼':<10} {'é¢„æµ‹å€¼':<10} {'è¯¯å·®':<10} {'è¯¯å·®ç‡%':<10}")
        print("-" * 50)
        for i in range(min(10, len(y_true_original))):
            actual = y_true_original[i]
            predicted = y_pred_original[i]
            error = abs(actual - predicted)
            error_rate = (error / actual * 100) if actual != 0 else np.inf
            print(f"{actual:<10.2f} {predicted:<10.2f} {error:<10.2f} {error_rate:<10.2f}%")
        
        # é‡æ–°è®­ç»ƒæ¨¡å‹ç”¨äºåç»­é¢„æµ‹ (åœ¨æ‰€æœ‰æ•°æ®å’Œé€‰å®šç‰¹å¾ä¸Šè®­ç»ƒæœ€ç»ˆæ¨¡å‹)
        self.model.fit(X_selected, y_scaled) # æ³¨æ„è¿™é‡Œæ˜¯X_selected
        
        self.results = {
            'model': self.model,
            'feature_scaler': None,
            'target_scaler': self.target_scaler,
            'overall_rmse': overall_rmse,
            'overall_mae': overall_mae,
            'overall_r2': overall_r2,
            'y_true_original': y_true_original,
            'y_pred_original': y_pred_original,
            'X_raw': X_raw, # åŸå§‹å·¥ç¨‹ç‰¹å¾ï¼Œç”¨äºä¿å­˜å’Œå‚è€ƒ
            'X_selected': X_selected, # é€‰å®šç‰¹å¾
            'selected_feature_indices': self.selected_feature_indices, # é€‰å®šç‰¹å¾çš„ç´¢å¼•
            'feature_importances': self.model.feature_importances_, # è¿™æ˜¯åœ¨é€‰å®šç‰¹å¾å­é›†ä¸Šçš„é‡è¦æ€§
            'use_log1p': True
        }
        
        return self.results

    def visualize_feature_importance(self, n_top=20):
        """å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§ (ç°åœ¨è€ƒè™‘RFEé€‰æ‹©åçš„ç‰¹å¾)"""
        if not self.results or self.selected_feature_indices is None:
            print("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–RFEæœªæ‰§è¡Œ")
            return
            
        feature_importances = self.results['feature_importances']
        
        # è·å–è¢«RFECVé€‰ä¸­çš„ç‰¹å¾åç§°
        selected_engineered_feature_names = np.array(self.engineered_feature_names)[self.selected_feature_indices]

        feature_df = pd.DataFrame({
            'feature_name': selected_engineered_feature_names,
            'importance': feature_importances
        }).sort_values('importance', ascending=False)
        
        top_features = feature_df.head(n_top)
        
        plt.figure(figsize=(12, 8))
        sns.barplot(x='importance', y='feature_name', data=top_features, palette='viridis')
        plt.xlabel('ç‰¹å¾é‡è¦æ€§')
        plt.ylabel('å·¥ç¨‹ç‰¹å¾åç§°')
        plt.title(f'å‰ {n_top} ä¸ªå·¥ç¨‹ç‰¹å¾é‡è¦æ€§ (RFECVé€‰æ‹©å)')
        plt.tight_layout()
        
        try:
            plt.savefig('feature_importance_rfe.png', dpi=300, bbox_inches='tight')
            print("ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜ä¸º feature_importance_rfe.png")
        except:
            print("ä¿å­˜å›¾ç‰‡å¤±è´¥ï¼Œä½†æ˜¾ç¤ºæ­£å¸¸")
        
        plt.show()

    def save_results_to_file(self, file_names, output_file='model_evaluation_results_rfe.txt'): # ä¿®æ”¹æ–‡ä»¶å
        """ä¿å­˜è¯„ä¼°ç»“æœåˆ°æ–‡ä»¶"""
        if not self.results:
            print("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
            return
            
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("éšæœºæ£®æ—æ¨¡å‹è¯„ä¼°æŠ¥å‘Š (å¸¦RFECVç‰¹å¾é€‰æ‹©)\n") # ä¿®æ”¹æ ‡é¢˜
            f.write("=" * 50 + "\n\n")
            
            f.write(f"æ•°æ®é›†ä¿¡æ¯:\n")
            f.write(f"  ç”µæ± æ ·æœ¬æ•°é‡: {len(self.results['y_true_original'])}\n")
            f.write(f"  åˆå§‹å·¥ç¨‹ç‰¹å¾æ•°é‡: {self.results['X_raw'].shape[1]}\n")
            f.write(f"  RFECVé€‰æ‹©çš„ç‰¹å¾æ•°é‡: {self.results['X_selected'].shape[1]}\n\n") # æ–°å¢
            
            f.write(f"æ¨¡å‹æ€§èƒ½æŒ‡æ ‡ (LOOCV, åŸå§‹å°ºåº¦):\n")
            f.write(f"  RMSE: {self.results['overall_rmse']:.4f}\n")
            f.write(f"  MAE:  {self.results['overall_mae']:.4f}\n")
            f.write(f"  RÂ²:   {self.results['overall_r2']:.4f}\n\n")
            
            f.write(f"è¯¦ç»†é¢„æµ‹ç»“æœ:\n")
            f.write(f"{'æ–‡ä»¶å':<30} {'å®é™…å€¼':<10} {'é¢„æµ‹å€¼':<10} {'ç»å¯¹è¯¯å·®':<10} {'è¯¯å·®ç‡%':<10}\n")
            f.write("-" * 75 + "\n")
            
            for i in range(len(self.results['y_true_original'])):
                actual = self.results['y_true_original'][i]
                predicted = self.results['y_pred_original'][i]
                error = abs(actual - predicted)
                error_rate = (error / actual * 100) if actual != 0 else np.inf
                f.write(f"{file_names[i]:<30} {actual:<10.2f} {predicted:<10.2f} {error:<10.2f} {error_rate:<10.2f}\n")

    def save_model(self, model_dir='models'):
        """ä¿å­˜æ¨¡å‹å’Œé¢„å¤„ç†å™¨"""
        if not self.results:
            print("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
            return
            
        Path(model_dir).mkdir(exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹å’Œç›®æ ‡å˜é‡æ ‡å‡†åŒ–å™¨
        with open(f'{model_dir}/final_rf_model_rfe.pkl', 'wb') as f: # ä¿®æ”¹æ–‡ä»¶å
            pickle.dump(self.model, f)
        with open(f'{model_dir}/target_scaler_rfe.pkl', 'wb') as f: # ä¿®æ”¹æ–‡ä»¶å
            pickle.dump(self.target_scaler, f)
        # ä¿å­˜é€‰æ‹©çš„ç‰¹å¾ç´¢å¼•ï¼Œä»¥ä¾¿é¢„æµ‹æ—¶ä½¿ç”¨
        with open(f'{model_dir}/selected_feature_indices.pkl', 'wb') as f:
            pickle.dump(self.selected_feature_indices, f)
    
        print(f"\næ¨¡å‹å’Œé¢„å¤„ç†å™¨å·²ä¿å­˜åˆ° {model_dir}/ ç›®å½•")
        print("ä¿å­˜çš„æ–‡ä»¶åŒ…æ‹¬:")
        print(f"- {model_dir}/final_rf_model_rfe.pkl: è®­ç»ƒå¥½çš„éšæœºæ£®æ—æ¨¡å‹ (RFEå)")
        print(f"- {model_dir}/target_scaler_rfe.pkl: ç›®æ ‡å˜é‡æ ‡å‡†åŒ–å™¨")
        print(f"- {model_dir}/selected_feature_indices.pkl: RFEé€‰æ‹©çš„ç‰¹å¾ç´¢å¼•")


    def predict(self, X_new):
        """å¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹"""
        if self.model is None or self.selected_feature_indices is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒæˆ–RFEæœªæ‰§è¡Œï¼Œè¯·å…ˆè°ƒç”¨è®­ç»ƒæ–¹æ³•")
        
        # å¯¹æ–°æ•°æ®ä¹Ÿåº”ç”¨ç›¸åŒçš„ç‰¹å¾é€‰æ‹©
        X_new_selected = X_new[:, self.selected_feature_indices]
    
        y_pred_scaled = self.model.predict(X_new_selected)
        
        y_pred_log1p = self.target_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
        
        y_pred_original = np.expm1(y_pred_log1p)
        
        y_pred_original = np.maximum(y_pred_original, 0)
        
        return y_pred_original

    def plot_prediction_results(self):
        """ç»˜åˆ¶é¢„æµ‹ç»“æœ"""
        if not self.results:
            print("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
            return
            
        y_true = self.results['y_true_original']
        y_pred = self.results['y_pred_original']
        r2 = self.results['overall_r2']
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))
        
        # å®é™…å€¼ vs é¢„æµ‹å€¼
        axes[0].scatter(y_true, y_pred, alpha=0.7, color='blue')
        max_val = max(y_true.max(), y_pred.max())
        min_val = min(y_true.min(), y_pred.min())
        axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)
        axes[0].set_xlabel('å®é™…å¾ªç¯æ•°')
        axes[0].set_ylabel('é¢„æµ‹å¾ªç¯æ•°')
        axes[0].set_title(f'LOOCV å®é™…å€¼ vs é¢„æµ‹å€¼ (RÂ² = {r2:.4f})')
        axes[0].grid(True, alpha=0.3)
        axes[0].set_aspect('equal', adjustable='box')

        # æ®‹å·®å›¾
        residuals = y_true - y_pred
        axes[1].scatter(y_pred, residuals, alpha=0.7, color='green')
        axes[1].axhline(y=0, color='r', linestyle='--')
        axes[1].set_xlabel('é¢„æµ‹å¾ªç¯æ•°')
        axes[1].set_ylabel('æ®‹å·® (å®é™…å€¼ - é¢„æµ‹å€¼)')
        axes[1].set_title('LOOCV æ®‹å·®å›¾')
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        try:
            plt.savefig('prediction_results_rfe.png', dpi=300, bbox_inches='tight')
            print("é¢„æµ‹ç»“æœå›¾å·²ä¿å­˜ä¸º prediction_results_rfe.png")
        except:
            print("ä¿å­˜å›¾ç‰‡å¤±è´¥ï¼Œä½†æ˜¾ç¤ºæ­£å¸¸")
        
        plt.show()

    def run_complete_pipeline(self):
        """è¿è¡Œå®Œæ•´çš„é¢„æµ‹æµæ°´çº¿"""
        try:
            # 1. åŠ è½½æ•°æ®
            early_data_list, final_cycle_counts, file_names = self.load_csv_data()
            
            # 2. ç‰¹å¾å·¥ç¨‹
            X_engineered = self.extract_battery_level_features(early_data_list, file_names)
            
            # 3. è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ (åŒ…å«RFECVç‰¹å¾é€‰æ‹©)
            self.train_and_evaluate_model_loocv(X_engineered, final_cycle_counts)
            
            # 4. å¯è§†åŒ–ç»“æœ
            self.plot_prediction_results()
            self.visualize_feature_importance()
            
            # 5. ä¿å­˜ç»“æœ
            self.save_results_to_file(file_names)
            self.save_model()
            
            print("\nâœ… å®Œæ•´çš„é¢„æµ‹æµæ°´çº¿æ‰§è¡Œå®Œæˆ!")
            print(f"ä½¿ç”¨RFECVé€‰æ‹©äº† {self.selected_feature_indices.sum()} ä¸ªæœ€ä½³ç‰¹å¾")
            
        except Exception as e:
            print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”‹ ç”µæ± å¯¿å‘½é¢„æµ‹æ¨¡å‹")
    print("=" * 50)
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = BatteryLifePredictionModel(
        data_folder=None,  # è‡ªåŠ¨æŸ¥æ‰¾æ•°æ®æ–‡ä»¶å¤¹
        num_early_cycles=40
    )
    
    # è¿è¡Œå®Œæ•´æµæ°´çº¿
    model.run_complete_pipeline()

if __name__ == "__main__":
    main()